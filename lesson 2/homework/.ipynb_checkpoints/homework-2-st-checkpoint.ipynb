{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. Преобразование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель этого задания -- преобразовать имеющиеся атрибуты пользователей в признаки так, чтобы полученная матрица признаков была пригодна для подачи в алгоритм кластеризации. Этап конструирования признаков -- самый важный и обычно самый долгий. К нему возвращаются много раз на протяжении решения задачи анализа данных.\n",
    "\n",
    "Кроме библиотек, использованных в первом задании, нам понадобятся следующие библиотеки:\n",
    "1. [scikit-learn](http://scikit-learn.org/stable/) -- библиотека, реализующая множество алгоритмов машинного обучения и сопутствующих алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import sklearn.preprocessing as sp\n",
    "import csv\n",
    "import re\n",
    "import dateutil\n",
    "\n",
    "np.set_printoptions(linewidth=150, precision=3, suppress=True)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts_parser = lambda date_str: datetime.datetime.strptime(date_str, \"%Y-%m\") if pd.notnull(date_str) and date_str else None\n",
    "df_users = pd.read_csv(\"hw1_out.csv\", sep=\"\\t\", encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC, converters={\"created_at\": ts_parser})\n",
    "# Remove rows with users not found\n",
    "df_users = df_users[pd.notnull(df_users['name'])]\n",
    "df_users[\"lat\"].fillna(value=0, inplace=True)\n",
    "df_users[\"lon\"].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо ввести новые признаки. Для каждого пользователя предлагается ввести следующие признаки:\n",
    "- name_words - количество слов в имени\n",
    "- screen_name_length - количество символов в псевдониме\n",
    "- description_length - длина описания\n",
    "- created_year - год создания аккаунта\n",
    "- country_code - код страны\n",
    "- verified - предлагается перевести в тип int\n",
    "\n",
    "(2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_count = 1\n",
    "country_map = {}\n",
    "for user_num, country in enumerate(df_users['country']):\n",
    "    if type(country) is not float and country not in country_map:\n",
    "        country_map[country] = country_count\n",
    "        country_count += 1\n",
    "df_users['country_code'] = [0 if type(x) is float else country_map[x] for x in df_users['country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_new_features(df_users, features):\n",
    "    # Introduce new features\n",
    "    new_features = [\"name_words\", \"screen_name_length\", \"description_length\", \"created_year\", \"country_code\", \"verified\"]\n",
    "    \n",
    "    df_users[\"name_words\"] = [len(x.split()) for x in df_users[\"name\"]]\n",
    "    df_users[\"screen_name_length\"] = [len(x) for x in df_users[\"name\"]]\n",
    "    df_users['description_length'] = [len('' if type(x) is float else x) for i,x in enumerate(df_users['description'])]\n",
    "    df_users[\"created_year\"] = [pd.to_datetime(x).year for x in df_users[\"created_at\"]]\n",
    "    country_count = 1\n",
    "    country_map = {}\n",
    "    for user_num, country in enumerate(df_users['country']):\n",
    "        if type(country) is not float and country not in country_map:\n",
    "            country_map[country] = country_count\n",
    "            country_count += 1\n",
    "    df_users['country_code'] = [0 if type(x) is float else country_map[x] for x in df_users['country']]\n",
    "    df_users[\"verified\"] = [int(x) for x in df_users[\"verified\"]]\n",
    "    \n",
    "    return df_users, features + [\"name_words\", \"screen_name_length\", \"created_year\", \"verified\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"lat\", \"lon\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "df_users, features = create_new_features(df_users, features)\n",
    "\n",
    "x = df_users[pd.notnull(df_users.cls)][features].values\n",
    "y = df_users[pd.notnull(df_users.cls)][\"cls\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>name_words</th>\n",
       "      <th>screen_name_length</th>\n",
       "      <th>created_year</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.74836</td>\n",
       "      <td>-82.70343</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>9481.0</td>\n",
       "      <td>21323.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.54860</td>\n",
       "      <td>103.52690</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>19294.0</td>\n",
       "      <td>7184.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.48095</td>\n",
       "      <td>-2.23743</td>\n",
       "      <td>632.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>7852.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>187955.0</td>\n",
       "      <td>88086.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>27013.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat        lon  followers_count  friends_count  statuses_count  \\\n",
       "0  27.74836  -82.70343           1052.0         1962.0          9481.0   \n",
       "1   1.54860  103.52690           1195.0          837.0         19294.0   \n",
       "2  53.48095   -2.23743            632.0          577.0          7852.0   \n",
       "3   0.00000    0.00000           2372.0         2436.0        187955.0   \n",
       "4   0.00000    0.00000           1251.0          969.0         36809.0   \n",
       "\n",
       "   favourites_count  listed_count  name_words  screen_name_length  \\\n",
       "0           21323.0          29.0           2                  10   \n",
       "1            7184.0         110.0           2                  12   \n",
       "2            1141.0          29.0           3                  13   \n",
       "3           88086.0          70.0           1                   1   \n",
       "4           27013.0          96.0           1                  17   \n",
       "\n",
       "   created_year  verified  \n",
       "0          2010         0  \n",
       "1          2013         0  \n",
       "2          2011         0  \n",
       "3          2013         0  \n",
       "4          2015         0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users[pd.notnull(df_users.cls)][features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, являются ли какие-либо из выбранных признаков сильно скоррелированными. Для этого посчитаем матрицу корреляций и выберем те пары признаков, абсолютное значения коэффициента корреляции между которыми больше 0.2. Необходимо реализовать функцию find_correlated_features, в которой нужно рассчитать коэффициенты корелляции и вывести те, которые больше 0.2. Подсказка: предлагается найти необходимую функцию в библиотеке np и реализовать find_correlated_features с использованием не более 5 строк кода (включая заголовок функции). (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_correlated_features(x, features):\n",
    "    # replace this code to find really correlated features\n",
    "    print np.corrcoef(df_users)\n",
    "    for i, feature_i in enumerate(features):\n",
    "        for j, feature_j in enumerate(features):\n",
    "            if i < j:\n",
    "                print \"Correlated features: %s + %s -> %.2f\" % (feature_i, feature_j, np.correlate(df_users[feature_i], df_users[feature_j]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Timestamp' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-1b4e5b05ab93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_correlated_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-212-37fcb07ce16b>\u001b[0m in \u001b[0;36mfind_correlated_features\u001b[0;34m(x, features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_correlated_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# replace this code to find really correlated features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anton/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof)\u001b[0m\n\u001b[1;32m   2559\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2560\u001b[0m                       DeprecationWarning)\n\u001b[0;32m-> 2561\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anton/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0maweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m     \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m     \u001b[0mw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anton/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anton/anaconda/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;32mpandas/tslib.pyx\u001b[0m in \u001b[0;36mpandas.tslib.Timestamp.__radd__ (pandas/tslib.c:14178)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Timestamp' and 'float'"
     ]
    }
   ],
   "source": [
    "find_correlated_features(x, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделилось 3 группы признаков:\n",
    "1. Основанные на географии:  \"lat\", \"lon\", \"country_code\"\n",
    "2. Основанные на социальной активности:  \"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"\n",
    "3. Остальные:  \"name_words\", \"screen_name_length\", \"description_length\"\n",
    "\n",
    "Построим взаимные распределения пар признаков в каждой из групп, а также гистограмму значений каждого из признаков с учетом целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать функции: plot_two_features_scatter для построения взаимного распределения пары признаков, plot_feature_histogram для построения гистограммы значений, plot_dataset для построения набора графиков по разным парам признаков. (4 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_two_features_scatter(x_i, x_j, y):\n",
    "    \n",
    "    # Set colors and plot scatter\n",
    "    # your code here\n",
    "    \n",
    "    pass    \n",
    "\n",
    "    \n",
    "def plot_feature_histogram(x_i, y):\n",
    "    \n",
    "    # Compute positive and negative histograms\n",
    "    # your code here\n",
    "    \n",
    "    # Plot stacked barplots\n",
    "    # your code here\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_dataset(x, y, features):\n",
    "    # Tune your plot if necessary\n",
    "    # your code here\n",
    "\n",
    "    for i, feature_i in enumerate(features):\n",
    "        for j, feature_j in enumerate(features):\n",
    "            \n",
    "            # Tune your plot if necessary (for example set labels)\n",
    "            # your code here\n",
    "            \n",
    "            # Do actual plotting\n",
    "            if i != j:\n",
    "                plot_two_features_scatter(x[:, i], x[:, j], y)            \n",
    "            else:\n",
    "                plot_feature_histogram(x[:, i], y)\n",
    "    \n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим попарные распределения географических признаков ([подсказка](http://stroykova.github.io/sphera/l2_1.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_features_new = [\"lat\", \"lon\", \"country_code\"]\n",
    "geo_features = [f for f in geo_features_new if f in features]\n",
    "\n",
    "geo_feature_ind = [i for i, f in enumerate(features) if f in geo_features]\n",
    "plot_dataset(x[:, geo_feature_ind], y, geo_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Четко видны очертания карты и то, что большинство пользователей происходят из небольшого набора стран. Если принять во внимание конечную цель -- кластеризацию пользователей -- логично предположить, что использование географических признаков для описания пользователя может оказаться не очень полезным. Причина в том, что эти признаки четко пространственно разделены (как минимум, океанами и морями). Поэтому мы рискуем вместо \"интересной\" кластеризации получить просто кластеры, которые будут представлять разные страны. В дальнейшем мы исключим географические признаки из рассмотрения при кластеризации пользователей.\n",
    "\n",
    "Далее построим попарные распределения социальных признаков ([подсказка](http://stroykova.github.io/sphera/l2_2.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "social_features_new = [\"verified\", \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\", \"created_year\"]\n",
    "social_features = [f for f in social_features_new if f in features]\n",
    "social_feature_ind = [i for i, f in enumerate(features) if f in social_features]\n",
    "plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков видно, что признаки \"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\" сильно смещены в сторону небольших значений. В таком случае удобно сделать логарифмическое преобразрвание этих признаков, то есть применить к их значениям $x_{ij}$ функцию $\\log(1 + x_{ij})$. Сделаем это и построим новые распределения ([подсказка](http://stroykova.github.io/sphera/l2_3.png)). Необходимо реализовать функцию log_transform_features, которая выполняет указанное логарифмическое преобразование. (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_transform_features(data, features, transformed_features):\n",
    "    # place your code here\n",
    "    # transform selected features with log function\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformed_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \"listed_count\"]\n",
    "x = log_transform_features(x, features, transformed_features)\n",
    "\n",
    "# Re-plot features\n",
    "plot_dataset(x[:, social_feature_ind], y, social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу бросается в глаза, что признак \"verified\" сильно смещен -- верифицированных пользователей очень мало. Более того, все верифицированные пользователи имеют много фолловеров, поэтому часть информации о верификации дублируется в признаке \"followers_count\". По этой причине в дальнейшем не будем рассматривать признак \"verified\".\n",
    "\n",
    "После того как мы с помощью логрифмического преобразования избавились от сильной скошенности признаков, можно наблюдать некоторые интересные зависимости. Например, пользователи, имеющие много фолловеров, обязательно имеют много статусов. Следовательно, чтобы стать популярным, обязательно нужно много писать. Анализ других зависимостей остается как упражнение.\n",
    "\n",
    "Наконец построим попарные распределения остальных признаков ([подсказка](http://stroykova.github.io/sphera/l2_4.png))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_features_new = [\"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "other_features = [f for f in other_features_new if f in features]\n",
    "other_feature_ind = [i for i, f in enumerate(features) if f in other_features]\n",
    "plot_dataset(x[:, other_feature_ind], y, other_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак после первичной обработки данных мы имеем 9 числовых признаков, каждый из которых распределен в некотором своем интервале. Для того, чтобы ни один признак не получил перевеса при кластеризации, нормализуем данные так, что каждый признак распределен на отрезке $[0, 1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features = [\"followers_count\", \"friends_count\", \"statuses_count\", \"favourites_count\", \n",
    "                     \"listed_count\", \"created_year\", \"name_words\", \"screen_name_length\", \"description_length\"]\n",
    "\n",
    "x_1 = df_users[selected_features].values\n",
    "y = df_users[\"cat\"].values\n",
    "\n",
    "# x_1 = x[:, selected_features_ind]\n",
    "# Replace nan with 0-s\n",
    "# Is there a smarter way?\n",
    "x_1[np.isnan(x_1)] = 0\n",
    "x_min = x_1.min(axis=0)\n",
    "x_max = x_1.max(axis=0)\n",
    "x_new = (x_1 - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упакуем полученную матрицу в pandas DataFrame и сохраним в файл \"hw2_out.csv\". В следующем задании мы будем кластеризовать пользователей на оновании этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(data=x_new, index=df_users[\"uid\"], columns=[f for f in selected_features])\n",
    "df_out.to_csv(\"hw2_out.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
